{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "architectural-seafood",
   "metadata": {},
   "source": [
    "### Objective "
   ]
  },
  {
   "cell_type": "raw",
   "id": "mineral-roller",
   "metadata": {},
   "source": [
    "Objective of this project is to build regression models using pyspark on patients details as to predict the medical cost based on other attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "august-double",
   "metadata": {},
   "source": [
    "#### Starting pyspark "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "three-noise",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark import SparkContext, SparkConf\n",
    "\n",
    "# Setup pyspark sc\n",
    "sc =SparkContext()\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "geographic-sapphire",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "raw",
   "id": "pressing-procedure",
   "metadata": {},
   "source": [
    "Attachment_1635667446.csv has been used as the dataset for this project. The file contains the patient details along with the medical cost."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loaded-participant",
   "metadata": {},
   "source": [
    "Command used to copy input CSV file into Hadoop File system is as below:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "built-environment",
   "metadata": {},
   "source": [
    "hadoop fs -put Attachment_1635667446.csv /"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conventional-fleet",
   "metadata": {},
   "source": [
    "### Loading the CSV data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "devoted-minnesota",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data load\n",
    "df = sqlContext.read.format('com.databricks.spark.csv')\\\n",
    "                    .option('header', 'true')\\\n",
    "                    .option('inferschema', 'true')\\\n",
    "                    .load('Attachment_1635667446.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "attractive-insurance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+--------+------+---------+-----------+\n",
      "|age|   sex|   bmi|children|smoker|   region|    charges|\n",
      "+---+------+------+--------+------+---------+-----------+\n",
      "| 19|female|  27.9|       0|   yes|southwest|  16884.924|\n",
      "| 18|  male| 33.77|       1|    no|southeast|  1725.5523|\n",
      "| 28|  male|  33.0|       3|    no|southeast|   4449.462|\n",
      "| 33|  male|22.705|       0|    no|northwest|21984.47061|\n",
      "| 32|  male| 28.88|       0|    no|northwest|  3866.8552|\n",
      "| 31|female| 25.74|       0|    no|southeast|  3756.6216|\n",
      "| 46|female| 33.44|       1|    no|southeast|  8240.5896|\n",
      "| 37|female| 27.74|       3|    no|northwest|  7281.5056|\n",
      "| 37|  male| 29.83|       2|    no|northeast|  6406.4107|\n",
      "| 60|female| 25.84|       0|    no|northwest|28923.13692|\n",
      "| 25|  male| 26.22|       0|    no|northeast|  2721.3208|\n",
      "| 62|female| 26.29|       0|   yes|southeast| 27808.7251|\n",
      "| 23|  male|  34.4|       0|    no|southwest|   1826.843|\n",
      "| 56|female| 39.82|       0|    no|southeast| 11090.7178|\n",
      "| 27|  male| 42.13|       0|   yes|southeast| 39611.7577|\n",
      "| 19|  male|  24.6|       1|    no|southwest|   1837.237|\n",
      "| 52|female| 30.78|       1|    no|northeast| 10797.3362|\n",
      "| 23|  male|23.845|       0|    no|northeast| 2395.17155|\n",
      "| 56|  male|  40.3|       0|    no|southwest|  10602.385|\n",
      "| 30|  male|  35.3|       0|   yes|southwest|  36837.467|\n",
      "+---+------+------+--------+------+---------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sample data\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rising-visitor",
   "metadata": {},
   "source": [
    "### Data pre-processing and transformation "
   ]
  },
  {
   "cell_type": "raw",
   "id": "identical-thunder",
   "metadata": {},
   "source": [
    "As part of data pre-processing missing or null values and data types have been handled as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "played-office",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "data_types = defaultdict(list)\n",
    "for entry in df.schema.fields:\n",
    "    data_types[str(entry.dataType)].append(entry.name)\n",
    "\n",
    "strings = data_types[\"StringType\"]\n",
    "\n",
    "# fill missing values with column averages\n",
    "missing_data_fill = {}\n",
    "for var in strings:\n",
    "    missing_data_fill[var] = \"missing\"\n",
    "df = df.fillna(missing_data_fill)\n",
    "\n",
    "numericals = data_types[\"DoubleType\"] + data_types[\"IntegerType\"] \\\n",
    "                                      + data_types[\"LongType\"]\n",
    "\n",
    "mean_dict = { col: 'mean' for col in numericals}\n",
    "col_avgs = df.agg( mean_dict ).collect()[0].asDict()\n",
    "col_avgs = { k[4:-1]: v for k,v in col_avgs.items() }\n",
    "df = df.fillna(col_avgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "confused-adelaide",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+--------+------+---------+-----------+\n",
      "|age|   sex|   bmi|children|smoker|   region|    charges|\n",
      "+---+------+------+--------+------+---------+-----------+\n",
      "| 19|female|  27.9|       0|   yes|southwest|  16884.924|\n",
      "| 18|  male| 33.77|       1|    no|southeast|  1725.5523|\n",
      "| 28|  male|  33.0|       3|    no|southeast|   4449.462|\n",
      "| 33|  male|22.705|       0|    no|northwest|21984.47061|\n",
      "| 32|  male| 28.88|       0|    no|northwest|  3866.8552|\n",
      "| 31|female| 25.74|       0|    no|southeast|  3756.6216|\n",
      "| 46|female| 33.44|       1|    no|southeast|  8240.5896|\n",
      "| 37|female| 27.74|       3|    no|northwest|  7281.5056|\n",
      "| 37|  male| 29.83|       2|    no|northeast|  6406.4107|\n",
      "| 60|female| 25.84|       0|    no|northwest|28923.13692|\n",
      "| 25|  male| 26.22|       0|    no|northeast|  2721.3208|\n",
      "| 62|female| 26.29|       0|   yes|southeast| 27808.7251|\n",
      "| 23|  male|  34.4|       0|    no|southwest|   1826.843|\n",
      "| 56|female| 39.82|       0|    no|southeast| 11090.7178|\n",
      "| 27|  male| 42.13|       0|   yes|southeast| 39611.7577|\n",
      "| 19|  male|  24.6|       1|    no|southwest|   1837.237|\n",
      "| 52|female| 30.78|       1|    no|northeast| 10797.3362|\n",
      "| 23|  male|23.845|       0|    no|northeast| 2395.17155|\n",
      "| 56|  male|  40.3|       0|    no|southwest|  10602.385|\n",
      "| 30|  male|  35.3|       0|   yes|southwest|  36837.467|\n",
      "+---+------+------+--------+------+---------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "developmental-workshop",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: integer (nullable = true)\n",
      " |-- sex: string (nullable = false)\n",
      " |-- bmi: double (nullable = false)\n",
      " |-- children: integer (nullable = true)\n",
      " |-- smoker: string (nullable = false)\n",
      " |-- region: string (nullable = false)\n",
      " |-- charges: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# schema of the data\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "increasing-abortion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age', 'sex', 'bmi', 'children', 'smoker', 'region', 'charges']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# variables list in the data\n",
    "variable_list_emblem = df.columns\n",
    "variable_list_emblem"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ethical-overhead",
   "metadata": {},
   "source": [
    "Numerical variables have been normalized and categorical variables have been transformed using one-hot encoder technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "italian-bench",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+--------+------+---------+-----------+------------------+---------------------+---------------------+-------------+--------------+--------------+--------------------+----------------------+---------------------+\n",
      "|age|   sex|   bmi|children|smoker|   region|    charges|sex_string_encoded|smoker_string_encoded|region_string_encoded|  sex_one_hot|smoker_one_hot|region_one_hot|          numericals|numericals_after_scale|normalized_numericals|\n",
      "+---+------+------+--------+------+---------+-----------+------------------+---------------------+---------------------+-------------+--------------+--------------+--------------------+----------------------+---------------------+\n",
      "| 19|female|  27.9|       0|   yes|southwest|  16884.924|               1.0|                  1.0|                  2.0|    (1,[],[])|     (1,[],[])| (3,[2],[1.0])|[19.0,27.9,0.0,16...|  [1.35231698077286...| [0.18469880297182...|\n",
      "| 18|  male| 33.77|       1|    no|southeast|  1725.5523|               0.0|                  0.0|                  0.0|(1,[0],[1.0])| (1,[0],[1.0])| (3,[0],[1.0])|[18.0,33.77,1.0,1...|  [1.28114240283745...| [0.16444129617166...|\n",
      "| 28|  male|  33.0|       3|    no|southeast|   4449.462|               0.0|                  0.0|                  0.0|(1,[0],[1.0])| (1,[0],[1.0])| (3,[0],[1.0])|[28.0,33.0,3.0,44...|  [1.99288818219159...| [0.19423176599492...|\n",
      "| 33|  male|22.705|       0|    no|northwest|21984.47061|               0.0|                  0.0|                  1.0|(1,[0],[1.0])| (1,[0],[1.0])| (3,[1],[1.0])|[33.0,22.705,0.0,...|  [2.34876107186866...| [0.29778665791226...|\n",
      "| 32|  male| 28.88|       0|    no|northwest|  3866.8552|               0.0|                  0.0|                  1.0|(1,[0],[1.0])| (1,[0],[1.0])| (3,[1],[1.0])|[32.0,28.88,0.0,3...|  [2.27758649393325...| [0.31060548996492...|\n",
      "+---+------+------+--------+------+---------+-----------+------------------+---------------------+---------------------+-------------+--------------+--------------+--------------------+----------------------+---------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n",
    "\n",
    "# One-hot encoding\n",
    "strings = [var for var in variable_list_emblem if var in data_types[\"StringType\"]]\n",
    "stage_string = [StringIndexer(inputCol= c, outputCol= c+\"_string_encoded\") for c in strings]\n",
    "stage_one_hot = [OneHotEncoder(inputCol= c+\"_string_encoded\", outputCol= c+ \"_one_hot\") for c in strings]\n",
    "\n",
    "ppl = Pipeline(stages= stage_string + stage_one_hot)\n",
    "df = ppl.fit(df).transform(df)\n",
    "\n",
    "from pyspark.ml.feature import Normalizer, VectorAssembler, StandardScaler\n",
    "\n",
    "numericals = [var for var in variable_list_emblem if var not in data_types[\"StringType\"]]\n",
    "numericals_out = [var+ \"_normalized\" for var in numericals]\n",
    "\n",
    "# Vector assembling numerical features\n",
    "vs = VectorAssembler(inputCols= numericals, outputCol= \"numericals\")\n",
    "df = vs.transform(df)\n",
    "\n",
    "scaler = StandardScaler(inputCol = \"numericals\", outputCol = \"numericals_after_scale\")\n",
    "normalizer = Normalizer(inputCol = \"numericals_after_scale\", outputCol= \"normalized_numericals\", p=1.0)\n",
    "\n",
    "ppl2 = Pipeline(stages= [scaler, normalizer])\n",
    "df = ppl2.fit(df).transform(df)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "native-theme",
   "metadata": {},
   "source": [
    "#### Splitting the data into training and testing sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "muslim-somerset",
   "metadata": {},
   "outputs": [],
   "source": [
    "categoricals = [var for var in df.columns if var.endswith(\"_one_hot\")]\n",
    "num = [\"numericals\"]\n",
    "vector_assembler = VectorAssembler(inputCols= categoricals + num, outputCol= \"features\")\n",
    "df = vector_assembler.transform(df)\n",
    "\n",
    "# 70% for training and 30% for testing \n",
    "training_set, test_set = df.randomSplit([0.7, 0.3], seed = 2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "annual-trance",
   "metadata": {},
   "source": [
    "### Model Build and Validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "waiting-rouge",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.regression import GeneralizedLinearRegression, GBTRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "#model definiton\n",
    "charges_medical =  GeneralizedLinearRegression(family=\"poisson\",\n",
    "                                           link=\"log\",\n",
    "                                           maxIter=10,\n",
    "                                           fitIntercept = True,\n",
    "                                           labelCol = \"charges\",\n",
    "                                           regParam=0.3)\n",
    "# Hyper-paramter tuning the model\n",
    "para_grid = ParamGridBuilder()\\\n",
    "           .addGrid(charges_medical.regParam, [0.1, 0.3, 0.5, 0.7, 0.9])\\\n",
    "           .build()\n",
    "\n",
    "# Model training evaluation\n",
    "evaluator = RegressionEvaluator(labelCol=\"charges\",\n",
    "                                predictionCol=\"prediction\",\n",
    "                                metricName=\"rmse\")\n",
    "\n",
    "cross_val = CrossValidator(estimator = charges_medical,\n",
    "                           estimatorParamMaps= para_grid,\n",
    "                           evaluator = evaluator)\n",
    "# Fitting the model on training set\n",
    "model_charges_medical = cross_val.fit(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bound-telescope",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction on the test set\n",
    "df_predictions = model_charges_medical.transform(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "military-holmes",
   "metadata": {},
   "source": [
    "#### Model performance validation on test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "scheduled-roads",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 6525.15\n",
      "R-square on test data = 0.821807\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "evaluator = RegressionEvaluator(\n",
    "    labelCol=\"charges\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(df_predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "prediction_to_pandas = df_predictions.select([\"prediction\",\"charges\"]).toPandas()\n",
    "r2 = r2_score(prediction_to_pandas.prediction, prediction_to_pandas.charges)\n",
    "print(\"R-square on test data = %g\" % r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faced-herald",
   "metadata": {},
   "source": [
    "### Conclusion "
   ]
  },
  {
   "cell_type": "raw",
   "id": "structured-sweden",
   "metadata": {},
   "source": [
    "As we can see from the above model performance on the test data the model has RMSE of 6525 and R2 value of 82% which means the model is able to explain 82% variance in the data in predicting the medical cost using other variables from patient details with low RMSE. \n",
    "\n",
    "With this project, end to end model development stages in pyspark using linear regression techniques have been understood.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executed-balance",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
